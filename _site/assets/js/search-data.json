{"0": {
    "doc": "Linting",
    "title": "Linting",
    "content": " ",
    "url": "/docs/rosemary/linting",
    
    "relUrl": "/docs/rosemary/linting"
  },"1": {
    "doc": "Linting",
    "title": "Table of contents",
    "content": ". | Check Python syntax | Using flake8 directly | . ",
    "url": "/docs/rosemary/linting#table-of-contents",
    
    "relUrl": "/docs/rosemary/linting#table-of-contents"
  },"2": {
    "doc": "Linting",
    "title": "Check Python syntax",
    "content": "rosemary linter . This command is designed to run the linter Flake8 in the app, rosemary and core directories to check the quality of the code. ",
    "url": "/docs/rosemary/linting#check-python-syntax",
    
    "relUrl": "/docs/rosemary/linting#check-python-syntax"
  },"3": {
    "doc": "Linting",
    "title": "Using flake8 directly",
    "content": "You can run flake8 directly on the desired directories. To do this, run: . flake8 app rosemary core . ",
    "url": "/docs/rosemary/linting#using-flake8-directly",
    
    "relUrl": "/docs/rosemary/linting#using-flake8-directly"
  },"4": {
    "doc": "Access MariaDB",
    "title": "Access MariaDB",
    "content": " ",
    "url": "/docs/rosemary/managing_database/access_mariadb",
    
    "relUrl": "/docs/rosemary/managing_database/access_mariadb"
  },"5": {
    "doc": "Access MariaDB",
    "title": "Table of contents",
    "content": ". | Access to console | Exit console | . ",
    "url": "/docs/rosemary/managing_database/access_mariadb#table-of-contents",
    
    "relUrl": "/docs/rosemary/managing_database/access_mariadb#table-of-contents"
  },"6": {
    "doc": "Access MariaDB",
    "title": "Access to console",
    "content": "To directly use the MariaDB console to execute native SQL statements, use: . rosemary db:console . This command connects to the MariaDB container using the credentials defined in the .env file. ",
    "url": "/docs/rosemary/managing_database/access_mariadb#access-to-console",
    
    "relUrl": "/docs/rosemary/managing_database/access_mariadb#access-to-console"
  },"7": {
    "doc": "Access MariaDB",
    "title": "Exit console",
    "content": "To exit the MariaDB console, type: . exit; . ",
    "url": "/docs/rosemary/managing_database/access_mariadb#exit-console",
    
    "relUrl": "/docs/rosemary/managing_database/access_mariadb#exit-console"
  },"8": {
    "doc": "Architecture",
    "title": "Architecture",
    "content": "Understanding the architecture of uvlhub is crucial for leveraging its full potential. This architecture is designed to create a seamless and robust platform that facilitates efficient model management, ensuring data integrity and accessibility. By comprehending the interplay of its components, users can better appreciate how uvlhub adheres to Open Science principles, supports extensive model analysis, and provides reliable data storage and retrieval. ",
    "url": "/docs/architecture",
    
    "relUrl": "/docs/architecture"
  },"9": {
    "doc": "CI/CD",
    "title": "CI/CD",
    "content": "Understanding the CI/CD pipeline of uvlhub , implemented using GitHub Actions, is essential for ensuring the seamless and efficient deployment of our application. CI/CD automates the process of testing, building, and deploying code changes, significantly reducing the risk of human error and increasing the speed of development cycles. By mastering the CI/CD setup, you can contribute to a more robust, reliable, and scalable application, ensuring that every code change is integrated smoothly and deployed swiftly. ",
    "url": "/docs/ci_cd",
    
    "relUrl": "/docs/ci_cd"
  },"10": {
    "doc": "Clearing files",
    "title": "Clearing files",
    "content": " ",
    "url": "/docs/rosemary/clearing_files",
    
    "relUrl": "/docs/rosemary/clearing_files"
  },"11": {
    "doc": "Clearing files",
    "title": "Table of contents",
    "content": ". | Clear cache | Clear log | Clear uploads | . ",
    "url": "/docs/rosemary/clearing_files#table-of-contents",
    
    "relUrl": "/docs/rosemary/clearing_files#table-of-contents"
  },"12": {
    "doc": "Clearing files",
    "title": "Clear cache",
    "content": "rosemary clear:cache . This command is used to clear the pytest cache in the app/blueprints directory and the build directory in the root of the project. After confirming the action, the command removes the .pytest_cache folder, the build folder, all __pycache__ directories and all .pyc files found in the project. ",
    "url": "/docs/rosemary/clearing_files#clear-cache",
    
    "relUrl": "/docs/rosemary/clearing_files#clear-cache"
  },"13": {
    "doc": "Clearing files",
    "title": "Clear log",
    "content": "rosemary clear:log . This command is used to clear the app.log file. ",
    "url": "/docs/rosemary/clearing_files#clear-log",
    
    "relUrl": "/docs/rosemary/clearing_files#clear-log"
  },"14": {
    "doc": "Clearing files",
    "title": "Clear uploads",
    "content": "rosemary clear:uploads . This command clears the uploads folder used by users to upload dataset files. ",
    "url": "/docs/rosemary/clearing_files#clear-uploads",
    
    "relUrl": "/docs/rosemary/clearing_files#clear-uploads"
  },"15": {
    "doc": "Commit syntax checker workflow",
    "title": "Commit syntax checker workflow",
    "content": "Path to file (view file on GitHub) . The original file is located at the following path: .github / workflows / commits.yml . This GitHub Actions workflow is designed to enforce conventional commit syntax on commits and pull requests. It triggers on various pull request events and pushes to the main branch. The essential elements of this workflow are as follows: . ",
    "url": "/docs/ci_cd/continuous_integration/commit_syntax_checker_workflow",
    
    "relUrl": "/docs/ci_cd/continuous_integration/commit_syntax_checker_workflow"
  },"16": {
    "doc": "Commit syntax checker workflow",
    "title": "Workflow Name",
    "content": ". | name: Commits Syntax Checker | . ",
    "url": "/docs/ci_cd/continuous_integration/commit_syntax_checker_workflow#workflow-name",
    
    "relUrl": "/docs/ci_cd/continuous_integration/commit_syntax_checker_workflow#workflow-name"
  },"17": {
    "doc": "Commit syntax checker workflow",
    "title": "Triggers",
    "content": ". | on: . | pull_request: Triggers on the following events for the main branch: . | opened | reopened | edited | review_requested | synchronize | . | push: Triggers on any push to the main branch. | workflow_call: Allows the workflow to be called by other workflows. | . | . ",
    "url": "/docs/ci_cd/continuous_integration/commit_syntax_checker_workflow#triggers",
    
    "relUrl": "/docs/ci_cd/continuous_integration/commit_syntax_checker_workflow#triggers"
  },"18": {
    "doc": "Commit syntax checker workflow",
    "title": "Jobs",
    "content": ". | check: This job runs on the latest Ubuntu environment (ubuntu-latest). | . Steps . | Checkout Repository . | Uses the actions/checkout@v2 action to checkout the repository. | . | Conventional Commits Check . | Uses the webiny/action-conventional-commits@v1.0.3 action to ensure that commit messages follow conventional commit standards. | . | . ",
    "url": "/docs/ci_cd/continuous_integration/commit_syntax_checker_workflow#jobs",
    
    "relUrl": "/docs/ci_cd/continuous_integration/commit_syntax_checker_workflow#jobs"
  },"19": {
    "doc": "Composing environment",
    "title": "Composing environment",
    "content": "It is possible to make a final composition of the .env file based on the individual .env files of each module. To execute this command and automatically combine the environment variables: . rosemary compose:env . Reboot required! . It is necessary to restart the application’s Docker container for the changes to take effect: . docker restart web_app_container . ",
    "url": "/docs/rosemary/extending_uvlhub/composing_environment",
    
    "relUrl": "/docs/rosemary/extending_uvlhub/composing_environment"
  },"20": {
    "doc": "Continuous deployment",
    "title": "Continuous deployment",
    "content": " ",
    "url": "/docs/ci_cd/continuous_deployment",
    
    "relUrl": "/docs/ci_cd/continuous_deployment"
  },"21": {
    "doc": "Continuous integration",
    "title": "Continuous integration",
    "content": " ",
    "url": "/docs/ci_cd/continuous_integration",
    
    "relUrl": "/docs/ci_cd/continuous_integration"
  },"22": {
    "doc": "Create module",
    "title": "Create module",
    "content": " ",
    "url": "/docs/rosemary/extending_uvlhub/create_module",
    
    "relUrl": "/docs/rosemary/extending_uvlhub/create_module"
  },"23": {
    "doc": "Create module",
    "title": "Table of contents",
    "content": ". | About | Create module | . ",
    "url": "/docs/rosemary/extending_uvlhub/create_module#table-of-contents",
    
    "relUrl": "/docs/rosemary/extending_uvlhub/create_module#table-of-contents"
  },"24": {
    "doc": "Create module",
    "title": "About",
    "content": "To quickly generate a new module within the project, including necessary boilerplate files like __init__.py, routes.py, models.py, repositories.py, services.py, forms.py, and a basic index.html template, you can use the rosemary CLI tool’s make:module command. This command will create a new blueprint structure ready for development. ",
    "url": "/docs/rosemary/extending_uvlhub/create_module#about",
    
    "relUrl": "/docs/rosemary/extending_uvlhub/create_module#about"
  },"25": {
    "doc": "Create module",
    "title": "Create module",
    "content": "To create a new module, run: . rosemary make:module &lt;module_name&gt; . Replace &lt;module_name&gt; with the desired name of your module. This command creates a new directory under app/blueprints/ with the name of your module and sets up the initial files and directories needed to get started, including a dedicated templates directory for your module’s templates. This feature is designed to streamline the development process, making it easy to add new features to the project. Note . If the module with &lt;module_name&gt; already exists, rosemary will simply notify you and not overwrite any existing files. Reboot required! . It is necessary to restart the application’s Docker container for the changes to take effect: . docker restart web_app_container . ",
    "url": "/docs/rosemary/extending_uvlhub/create_module",
    
    "relUrl": "/docs/rosemary/extending_uvlhub/create_module"
  },"26": {
    "doc": "Deployment",
    "title": "Deployment",
    "content": "Knowing how to deploy applications on platforms like Render and PythonAnywhere is crucial for any developer, as it bridges the gap between development and production, ensuring your code runs efficiently and securely in real-world environments. These platforms simplify the deployment process with automation tools, enabling continuous integration and continuous deployment (CI/CD), which enhances productivity by allowing rapid updates. ",
    "url": "/docs/deployment",
    
    "relUrl": "/docs/deployment"
  },"27": {
    "doc": "Deployment in PythonAnywhere",
    "title": "Deployment in PythonAnywhere",
    "content": "Coming soon… . ",
    "url": "/docs/deployment/pythonanywhere",
    
    "relUrl": "/docs/deployment/pythonanywhere"
  },"28": {
    "doc": "Deployment in Render",
    "title": "Deployment in Render",
    "content": "Coming soon… . ",
    "url": "/docs/deployment/render",
    
    "relUrl": "/docs/deployment/render"
  },"29": {
    "doc": "Deployment in server",
    "title": "Deployment in server",
    "content": " ",
    "url": "/docs/deployment/server",
    
    "relUrl": "/docs/deployment/server"
  },"30": {
    "doc": "Deployment in server",
    "title": "Table of contents",
    "content": ". | Clone the repo | Environment variables | Deploy containers | Watchdog available | . Required Docker installation . You need to have Docker and Docker Compose installed on the server where you want to deploy uvlhub . ",
    "url": "/docs/deployment/server#table-of-contents",
    
    "relUrl": "/docs/deployment/server#table-of-contents"
  },"31": {
    "doc": "Deployment in server",
    "title": "Clone the repo",
    "content": "git clone https://www.github.com/diverso-lab/uvlhub . ",
    "url": "/docs/deployment/server#clone-the-repo",
    
    "relUrl": "/docs/deployment/server#clone-the-repo"
  },"32": {
    "doc": "Deployment in server",
    "title": "Environment variables",
    "content": "It is necessary to configure the environment variables file in a production environment. These variables are crucial to define specific configurations of the production environment. cp .env.docker.production.example .env . Don’t forget to define the variables! . You need to properly define the values of the variables indicated with &lt;CHANGE_THIS&gt; in the .env file. ",
    "url": "/docs/deployment/server#environment-variables",
    
    "relUrl": "/docs/deployment/server#environment-variables"
  },"33": {
    "doc": "Deployment in server",
    "title": "Deploy containers",
    "content": "This process includes building and deploying the services defined in the Docker configuration file for the production environment. To deploy the application to production, run: . docker compose -f docker/docker-compose.prod.yml up -d --build . ",
    "url": "/docs/deployment/server#deploy-containers",
    
    "relUrl": "/docs/deployment/server#deploy-containers"
  },"34": {
    "doc": "Deployment in server",
    "title": "Watchdog available",
    "content": "The production deployment includes a Watchdog container provided by Watchtower (more info). This container is responsible for monitoring changes to Docker images in Docker Hub. When it detects a new version of an image, it automatically updates and restarts the affected containers. This functionality is particularly useful for deploying continuous deployments, ensuring that you are always using the latest version of the software without manual intervention. Important considerations . | The production environment uses Gunicorn. Gunicorn is a WSGI (Web Server Gateway Interface) HTTP server for Python applications that allows multiple requests to be handled simultaneously in production environments. | Rosemary is a development package, so it is not available in production for security reasons. | The test database is also not available. | The production environment is deployed without any populated test data for security reasons. | Debug mode is disabled, so no specific error trace will be shown, only a generic error of type 4xx or 5xx. | . ",
    "url": "/docs/deployment/server#watchdog-available",
    
    "relUrl": "/docs/deployment/server#watchdog-available"
  },"35": {
    "doc": "Docker",
    "title": "Docker",
    "content": " ",
    "url": "/docs/troubleshooting/docker",
    
    "relUrl": "/docs/troubleshooting/docker"
  },"36": {
    "doc": "Docker",
    "title": "Table of contents",
    "content": ". | Error response from daemon: driver failed programming external connectivity on endpoint mariadb_container (XXX): Error starting userland proxy: listen tcp4 0.0.0.0:3306: bind: address already in use . | Identify the process using port 3306 | Kill process | Disable MariaDB | . | . ",
    "url": "/docs/troubleshooting/docker#table-of-contents",
    
    "relUrl": "/docs/troubleshooting/docker#table-of-contents"
  },"37": {
    "doc": "Docker",
    "title": "Error response from daemon: driver failed programming external connectivity on endpoint mariadb_container (XXX): Error starting userland proxy: listen tcp4 0.0.0.0:3306: bind: address already in use",
    "content": "This occurs because there is already a process on port 3306 (typically because MariaDB has been installed manually). Identify the process using port 3306 . sudo lsof -i :3306 . With this we find out the PID identifier of the process running on 3306 . Kill process . sudo kill -9 &lt;PID&gt; . Disable MariaDB . If you have installed uvlhub manually and you are not going to use this deployment anymore, it is convenient to disable the MariaDB process: . sudo systemctl stop mariadb sudo systemctl disable mariadb . ",
    "url": "/docs/troubleshooting/docker#error-response-from-daemon-driver-failed-programming-external-connectivity-on-endpoint-mariadb_container-xxx-error-starting-userland-proxy-listen-tcp4-00003306-bind-address-already-in-use",
    
    "relUrl": "/docs/troubleshooting/docker#error-response-from-daemon-driver-failed-programming-external-connectivity-on-endpoint-mariadb_container-xxx-error-starting-userland-proxy-listen-tcp4-00003306-bind-address-already-in-use"
  },"38": {
    "doc": "Docker Hub workflow",
    "title": "Docker Hub workflow",
    "content": "Path to file (view file on GitHub) . The original file is located at the following path: .github / workflows / deployment.yml . To register secrets in GitHub: . | Navigate to your repository on GitHub. | Click on Settings. | In the left sidebar, click on Secrets and variables and then Actions. | Click the New repository secret button. | Add a name for your secret (e.g., DOCKER_USER) and its value. | Click Add secret to save. | . Repeat these steps for DOCKER_PASSWORD secret. This GitHub Actions workflow is designed to automate the process of building and publishing Docker images to Docker Hub whenever a new release is published. The essential elements of this workflow are as follows: . ",
    "url": "/docs/ci_cd/continuous_deployment/dockerHub_workflow",
    
    "relUrl": "/docs/ci_cd/continuous_deployment/dockerHub_workflow"
  },"39": {
    "doc": "Docker Hub workflow",
    "title": "Workflow Name",
    "content": ". | name: Publish Docker image | . ",
    "url": "/docs/ci_cd/continuous_deployment/dockerHub_workflow#workflow-name",
    
    "relUrl": "/docs/ci_cd/continuous_deployment/dockerHub_workflow#workflow-name"
  },"40": {
    "doc": "Docker Hub workflow",
    "title": "Triggers",
    "content": ". | on: . | release: Triggers when a release is published. | . | . ",
    "url": "/docs/ci_cd/continuous_deployment/dockerHub_workflow#triggers",
    
    "relUrl": "/docs/ci_cd/continuous_deployment/dockerHub_workflow#triggers"
  },"41": {
    "doc": "Docker Hub workflow",
    "title": "Jobs",
    "content": ". | push_to_registry: This job runs on the latest Ubuntu environment (ubuntu-latest). | . Steps . | Check out the Repository . | Uses the actions/checkout@v3 action to checkout the repository. | . | Log in to Docker Hub . | Uses the docker/login-action pinned to a specific commit (f4ef78c080cd8ba55a85445d5b36e214a81df20a) to log in to Docker Hub with credentials stored in GitHub Secrets: username: $ password: $ . | . | Build and Push Docker Image . | Builds the Docker image using the Dockerfile.prod file and tags it with the release tag name: docker build -t drorganvidez/uvlhub:$ -f Dockerfile.prod . | Pushes the tagged Docker image to Docker Hub: docker push drorganvidez/uvlhub:$ . | . | Tag and Push Latest . | Tags the built Docker image with latest and pushes it to Docker Hub: docker tag drorganvidez/uvlhub:$ drorganvidez/uvlhub:latest docker push drorganvidez/uvlhub:latest . | . | . Notes . | Third-Party Actions: This workflow uses third-party actions that are not certified by GitHub. They are governed by separate terms of service, privacy policy, and support documentation. | Pinning Actions: GitHub recommends pinning actions to a commit SHA to ensure stability and predictability. The workflow uses a pinned commit SHA for the Docker login action. | . ",
    "url": "/docs/ci_cd/continuous_deployment/dockerHub_workflow#jobs",
    
    "relUrl": "/docs/ci_cd/continuous_deployment/dockerHub_workflow#jobs"
  },"42": {
    "doc": "Extending uvlhub",
    "title": "Extending uvlhub",
    "content": " ",
    "url": "/docs/rosemary/extending_uvlhub",
    
    "relUrl": "/docs/rosemary/extending_uvlhub"
  },"43": {
    "doc": "Fakenodo",
    "title": "Fakenodo",
    "content": " ",
    "url": "/docs/modules/fakenodo",
    
    "relUrl": "/docs/modules/fakenodo"
  },"44": {
    "doc": "Getting started",
    "title": "Getting started",
    "content": " ",
    "url": "/docs/getting-started/",
    
    "relUrl": "/docs/getting-started/"
  },"45": {
    "doc": "Getting started",
    "title": "Table of contents",
    "content": ". | Clone repo | Environment variables | Deploy in develop | . For development deployment, the use of Docker is recommended. ",
    "url": "/docs/getting-started/#table-of-contents",
    
    "relUrl": "/docs/getting-started/#table-of-contents"
  },"46": {
    "doc": "Getting started",
    "title": "Clone repo",
    "content": "You can start your fantastic development with uvlhub by cloning our official repository. git clone https://github.com/diverso-lab/uvlhub.git cd uvlhub . ",
    "url": "/docs/getting-started/#clone-repo",
    
    "relUrl": "/docs/getting-started/#clone-repo"
  },"47": {
    "doc": "Getting started",
    "title": "Environment variables",
    "content": "To create an .env file according to a basic template, run: . cp .env.docker.example .env . ",
    "url": "/docs/getting-started/#environment-variables",
    
    "relUrl": "/docs/getting-started/#environment-variables"
  },"48": {
    "doc": "Getting started",
    "title": "Deploy in develop",
    "content": "To deploy the software under development environment, run: . docker compose -f docker/docker-compose.dev.yml up -d . This will apply the migrations to the database and run the Flask application. If everything worked correctly, you should see the deployed version of uvlhub in development at http://localhost . ",
    "url": "/docs/getting-started/#deploy-in-develop",
    
    "relUrl": "/docs/getting-started/#deploy-in-develop"
  },"49": {
    "doc": "GUI tests",
    "title": "GUI tests",
    "content": " ",
    "url": "/docs/rosemary/testing/gui_tests",
    
    "relUrl": "/docs/rosemary/testing/gui_tests"
  },"50": {
    "doc": "GUI tests",
    "title": "Table of contents",
    "content": ". | Introduction to Selenium | Interface test in local environment | Interface testing in Docker and Vagrant environment . | Activate the virtual environment | Install dependencies | Run test | . | Selenium IDE . | Installation | Recording a test | Playback the recorded test | Exporting the test script | Using the test in the project | . | Using WSL2 (Windows Subsystem for Linux) and WebDriver . | Install Google Chrome version 114 | Install ChromeDriver | Unzip and make ChromeDriver executable | Move the ChromeDriver executable to the WSL2 path | . | . ",
    "url": "/docs/rosemary/testing/gui_tests#table-of-contents",
    
    "relUrl": "/docs/rosemary/testing/gui_tests#table-of-contents"
  },"51": {
    "doc": "GUI tests",
    "title": "Introduction to Selenium",
    "content": "Selenium is a suite of web browser automation tools. It provides an easy-to-use interface for interacting with browsers such as Chrome, Firefox and Safari, enabling automated testing, data scraping and other repetitive tasks in web applications. ",
    "url": "/docs/rosemary/testing/gui_tests#introduction-to-selenium",
    
    "relUrl": "/docs/rosemary/testing/gui_tests#introduction-to-selenium"
  },"52": {
    "doc": "GUI tests",
    "title": "Interface test in local environment",
    "content": "To perform all interface tests in local environment, use: . rosemary selenium . You can run an interface test of a specific module: . rosemary selenium &lt;module_name&gt; . ",
    "url": "/docs/rosemary/testing/gui_tests#interface-test-in-local-environment",
    
    "relUrl": "/docs/rosemary/testing/gui_tests#interface-test-in-local-environment"
  },"53": {
    "doc": "GUI tests",
    "title": "Interface testing in Docker and Vagrant environment",
    "content": "Rosemary CLI not available . Currently it is not possible to use Rosemary CLI to run Selenium in Docker and/or Vagrant environment. This is a feature that will be added in the future. You have to do this in the local environment. Activate the virtual environment . It is recommended to use the virtual environment. python -m venv venv source venv/bin/activate . Install dependencies . pip install -r requirements.txt pip install -e ./ . Run test . To run the interface test of a module in this environment, run: . python app/blueprints/&lt;module_name&gt;/tests/test_selenium.py . Remember to replace &lt;module_name&gt; with the name of the module you want to test. ",
    "url": "/docs/rosemary/testing/gui_tests#interface-testing-in-docker-and-vagrant-environment",
    
    "relUrl": "/docs/rosemary/testing/gui_tests#interface-testing-in-docker-and-vagrant-environment"
  },"54": {
    "doc": "GUI tests",
    "title": "Selenium IDE",
    "content": "Selenium IDE (Integrated Development Environment) is a tool for recording, editing, and debugging web application tests. It is a browser extension available for both Chrome and Firefox that allows users to create test cases quickly without any programming knowledge. Selenium IDE is particularly useful for creating simple and quick tests, making it an excellent choice for beginners. Installation . | Chrome: Install the Selenium IDE extension from the Chrome Web Store. | Firefox: Install the Selenium IDE extension from the Firefox Add-ons. | . Recording a test . | Open Selenium IDE: After installation, click on the Selenium IDE icon in the browser toolbar to open it. | Create a new project: . | Click on Create a new project. | Name your project and click OK. | . | Start recording: . | Click on the Record a new test in a new project button. | Enter the base URL of your application, e.g., http://localhost, and click Start Recording. | . | Navigate to the desired page: . | In the browser, go to the page you want to test. | Selenium IDE will record your navigation to this page. | . | Perform actions: . | Perform the actions you want to test. Selenium IDE will record each of these actions. | . | Stop recording: . | Once you have performed all the necessary actions, click on the Stop recording button in Selenium IDE. | . | Save the test: . | Name your test case and save it. | . | . Playback the recorded test . | Select the test case: In Selenium IDE, select the test case you want to playback. | Run the Test: Click on the Run current test button. Selenium IDE will execute the recorded actions. | . Exporting the test script . If you want to export the test script for use with Selenium WebDriver, follow these steps: . | Click on the Export button. | Choose Python pytest and location to save the file in app/blueprints/&lt;module_name&gt;/tests/test_selenium/ | . Using the test in the project . You have to do this in the local environment. | Adjust the generated test | . Remember to adjust the generated test to the project. def setup_method(self, method): self.driver = initialize_driver() self.vars = {} . self.driver.get(get_host_for_selenium_testing()) . | Run the test with pytest. | . pytest --noconftest app/blueprints/auth/tests/test_selenium_ide/test_signup.py . Selenium IDE makes it easy to create, edit, and run automated tests for web applications, providing a great starting point for anyone new to test automation. ",
    "url": "/docs/rosemary/testing/gui_tests#selenium-ide",
    
    "relUrl": "/docs/rosemary/testing/gui_tests#selenium-ide"
  },"55": {
    "doc": "GUI tests",
    "title": "Using WSL2 (Windows Subsystem for Linux) and WebDriver",
    "content": "Install Google Chrome version 114 . cd $HOME wget --no-verbose -O /tmp/chrome.deb https://dl.google.com/linux/chrome/deb/pool/main/g/google-chrome-stable/google-chrome-stable_114.0.5735.198-1_amd64.deb &amp;&amp; sudo apt install -y /tmp/chrome.deb &amp;&amp; rm /tmp/chrome.deb . Install ChromeDriver . chrome_driver=\"114.0.5735.90\" curl -Lo chromedriver_linux64.zip \"https://chromedriver.storage.googleapis.com/${chrome_driver}/chromedriver_linux64.zip\" . Unzip and make ChromeDriver executable . mkdir -p \"chromedriver/stable\" &amp;&amp; \\ unzip -q \"chromedriver_linux64.zip\" -d \"chromedriver/stable\" &amp;&amp; \\ chmod +x \"chromedriver/stable/chromedriver\" . Move the ChromeDriver executable to the WSL2 path . sudo cp ~/chromedriver/stable/chromedriver /usr/bin/ . ",
    "url": "/docs/rosemary/testing/gui_tests#using-wsl2-windows-subsystem-for-linux-and-webdriver",
    
    "relUrl": "/docs/rosemary/testing/gui_tests#using-wsl2-windows-subsystem-for-linux-and-webdriver"
  },"56": {
    "doc": "Home",
    "title": "Welcome to uvlhub docs!",
    "content": "Welcome to the official documentation for uvlhub , your comprehensive repository for feature models in UVL format. Integrated seamlessly with Zenodo for robust data storage and flamapy from DiversoLab for advanced model analysis, uvlhub empowers researchers and developers with tools that adhere to Open Science principles. Dive in to explore how uvlhub can streamline your workflow, enhance collaboration, and drive innovation in feature model management. Get started now View it on GitHub . Changelog . Detailed changes for each release are documented in the release notes. ",
    "url": "/#welcome-to-uvlhub-docs",
    
    "relUrl": "/#welcome-to-uvlhub-docs"
  },"57": {
    "doc": "Home",
    "title": "Home",
    "content": " ",
    "url": "/",
    
    "relUrl": "/"
  },"58": {
    "doc": "Installation",
    "title": "Installation",
    "content": "Understanding how to install uvlhub is an essential skill that will enhance your technical proficiency and broaden your knowledge base. Whether you are setting up a local environment manually, using Docker, or deploying with Vagrant, mastering these installation methods brings several benefits. Hands-On Installation . Learning to install uvlhub manually helps you: . | Gain In-Depth Understanding: By installing uvlhub step-by-step, you get a deep understanding of its underlying components and dependencies. | Troubleshoot Effectively: When you know how each part fits together, you can troubleshoot issues more effectively and keep your environment running smoothly. | Customize Configurations: Manual installation allows you to tailor the setup to meet your specific needs and preferences. | . Using Docker . Installing uvlhub with Docker provides: . | Simplified Setup: Docker encapsulates all dependencies and configurations, simplifying the installation process. | Consistency Across Environments: Docker ensures that your development, testing, and production environments are identical, reducing the “it works on my machine” problem. | Scalability and Portability: Easily scale your applications and move them across different environments without worrying about compatibility issues. | . Deploying with Vagrant . Learning to deploy uvlhub with Vagrant offers: . | Automated Environment Provisioning: Vagrant automates the setup of your virtual environments, saving time and reducing human error. | Reproducibility: Vagrant allows you to create reproducible and portable work environments, ensuring that everyone on your team works in the same environment. | Ease of Use: With Vagrant, you can manage and switch between different project environments effortlessly, making your development workflow more efficient. | . By becoming proficient in these installation methods, you not only enhance your technical skills but also prepare yourself to tackle a wide range of challenges in various development and deployment scenarios. Embrace the opportunity to learn and master these installation techniques to stay ahead in the ever-evolving tech landscape. ",
    "url": "/docs/installation",
    
    "relUrl": "/docs/installation"
  },"59": {
    "doc": "Installation with Docker",
    "title": "Installation with Docker",
    "content": " ",
    "url": "/docs/installation/installation_with_docker",
    
    "relUrl": "/docs/installation/installation_with_docker"
  },"60": {
    "doc": "Installation with Docker",
    "title": "Table of contents",
    "content": ". | Set environment files | Run the containers | See containers in execution | Down the containers | . Required Docker installation . You need to have Docker and Docker Compose installed on the machine where you want to deploy uvlhub . Only for a development environment . This manual is intended for a development environment. For a production environment, visit Deployment. ",
    "url": "/docs/installation/installation_with_docker#table-of-contents",
    
    "relUrl": "/docs/installation/installation_with_docker#table-of-contents"
  },"61": {
    "doc": "Installation with Docker",
    "title": "Set environment files",
    "content": "First, copy the .env.docker.example file to the .env file that will be used to set the environment variables. cp .env.docker.example .env . ",
    "url": "/docs/installation/installation_with_docker#set-environment-files",
    
    "relUrl": "/docs/installation/installation_with_docker#set-environment-files"
  },"62": {
    "doc": "Installation with Docker",
    "title": "Run the containers",
    "content": "To start containers in development mode, use the docker-compose.dev.yml file located in the docker directory. The command will run in the background (-d). docker compose -f docker/docker-compose.dev.yml up -d . ",
    "url": "/docs/installation/installation_with_docker#run-the-containers",
    
    "relUrl": "/docs/installation/installation_with_docker#run-the-containers"
  },"63": {
    "doc": "Installation with Docker",
    "title": "See containers in execution",
    "content": "To verify that the containers are running correctly, use the following command: . docker ps . If everything worked correctly, you should see the deployed version of uvlhub in development at http://localhost . ",
    "url": "/docs/installation/installation_with_docker#see-containers-in-execution",
    
    "relUrl": "/docs/installation/installation_with_docker#see-containers-in-execution"
  },"64": {
    "doc": "Installation with Docker",
    "title": "Down the containers",
    "content": "To download (stop) the containers, use the same docker-compose.dev.yml file with the following command: . docker compose -f docker/docker-compose.dev.yml down . ",
    "url": "/docs/installation/installation_with_docker#down-the-containers",
    
    "relUrl": "/docs/installation/installation_with_docker#down-the-containers"
  },"65": {
    "doc": "Installation with Vagrant",
    "title": "Installation with Vagrant",
    "content": " ",
    "url": "/docs/installation/installation_with_vagrant",
    
    "relUrl": "/docs/installation/installation_with_vagrant"
  },"66": {
    "doc": "Installation with Vagrant",
    "title": "Table of contents",
    "content": ". | Set environment files | Working with Vagrant . | Run the VM | Accessing the VM | Provision the VM | See VM status | Halt the VM | Destroy the VM | . | . Required Vagrant, Ansible and VirtualBox installation . You need to have Vagrant, Ansible and VirtualBox installed on the machine where you want to deploy uvlhub . Only for a development environment . This manual is intended for a development environment. For a production environment, visit Deployment. ",
    "url": "/docs/installation/installation_with_vagrant#table-of-contents",
    
    "relUrl": "/docs/installation/installation_with_vagrant#table-of-contents"
  },"67": {
    "doc": "Installation with Vagrant",
    "title": "Set environment files",
    "content": "First, copy the .env.vagrant.example file to the .env file that will be used to set the environment variables. cp .env.vagrant.example .env . ",
    "url": "/docs/installation/installation_with_vagrant#set-environment-files",
    
    "relUrl": "/docs/installation/installation_with_vagrant#set-environment-files"
  },"68": {
    "doc": "Installation with Vagrant",
    "title": "Working with Vagrant",
    "content": "vagrant folder . All Vagrant commands must be executed inside the vagrant folder located in the root of the project. cd vagrant . Run the VM . To start the virtual machine in development mode, use the Vagrantfile located in vagrant folder. The command will set up and run the VM. vagrant up . If everything worked correctly, you should see the deployed version of uvlhub in development at http://localhost:5000 . Accessing the VM . To access the VM and execute operations from within (such as rosemary), run: . vagrant ssh . This will switch to the internal MV console. To exit, run: . exit . Provision the VM . If you need to run the provisioning scripts again (*.yml) (e.g., after making changes to them), use the following command: . vagrant up --provision . See VM status . To verify that the virtual machine is running correctly, use the following command: . vagrant status . Halt the VM . To halt (stop) the virtual machine, use the following command: . vagrant halt . Destroy the VM . To destroy the virtual machine (removing all data), use the following command: . vagrant destroy . Following these steps, you should be able to set up, run, and manage your Vagrant virtual machine efficiently. ",
    "url": "/docs/installation/installation_with_vagrant#working-with-vagrant",
    
    "relUrl": "/docs/installation/installation_with_vagrant#working-with-vagrant"
  },"69": {
    "doc": "Linter workflow",
    "title": "Linter workflow",
    "content": "Path to file (view file on GitHub) . The original file is located at the following path: .github / workflows / lint.yml . This GitHub Actions workflow is designed to automate the linting process for a Python application using flake8. It triggers on both pushes and pull requests. The essential elements of this workflow are as follows: . ",
    "url": "/docs/ci_cd/continuous_integration/linter_workflow",
    
    "relUrl": "/docs/ci_cd/continuous_integration/linter_workflow"
  },"70": {
    "doc": "Linter workflow",
    "title": "Workflow Name",
    "content": ". | name: Python Lint | . ",
    "url": "/docs/ci_cd/continuous_integration/linter_workflow#workflow-name",
    
    "relUrl": "/docs/ci_cd/continuous_integration/linter_workflow#workflow-name"
  },"71": {
    "doc": "Linter workflow",
    "title": "Triggers",
    "content": ". | on: . | push: Triggers on any push to the repository. | pull_request: Triggers on any pull request to the repository. | . | . ",
    "url": "/docs/ci_cd/continuous_integration/linter_workflow#triggers",
    
    "relUrl": "/docs/ci_cd/continuous_integration/linter_workflow#triggers"
  },"72": {
    "doc": "Linter workflow",
    "title": "Jobs",
    "content": ". | build: This job runs on the latest Ubuntu environment (ubuntu-latest). | . Steps . | Checkout Repository . | Uses the actions/checkout@v2 action to checkout the repository. | . | Set up Python . | Uses the actions/setup-python@v2 action to set up Python 3.x. | . | Install Dependencies . | Upgrades pip and installs flake8 using the following commands: python -m pip install --upgrade pip pip install flake8 . | . | Lint with flake8 . | Runs flake8 on the app directory to lint the Python code: flake8 app . | . | . ",
    "url": "/docs/ci_cd/continuous_integration/linter_workflow#jobs",
    
    "relUrl": "/docs/ci_cd/continuous_integration/linter_workflow#jobs"
  },"73": {
    "doc": "Load tests",
    "title": "Load tests",
    "content": " ",
    "url": "/docs/rosemary/testing/load_tests",
    
    "relUrl": "/docs/rosemary/testing/load_tests"
  },"74": {
    "doc": "Load tests",
    "title": "Table of contents",
    "content": ". | Introduction to Locust . | Key Features: | Ramp-Up in Locust | . | Run all load tests | Run load tests from specific module | Stop Locust | Official documentation | . ",
    "url": "/docs/rosemary/testing/load_tests#table-of-contents",
    
    "relUrl": "/docs/rosemary/testing/load_tests#table-of-contents"
  },"75": {
    "doc": "Load tests",
    "title": "Introduction to Locust",
    "content": "Locust is an open-source load testing tool that allows you to define user behavior with Python code and swarm your system with millions of simultaneous users. It’s useful for testing the performance of web applications and identifying potential bottlenecks. Key Features: . | Scalability: Capable of simulating millions of users. | Flexibility: User behavior can be defined with simple Python code. | Real-time Monitoring: Provides real-time statistics and metrics during the test. | . Ramp-Up in Locust . Ramp-up refers to the gradual increase in the number of simulated users over a specified period. This approach helps in observing how the system behaves as the load increases incrementally, rather than being hit with the maximum load all at once. Using Locust with your development environment . Load tests can be executed from any environment. To use the appropriate environment with Rosemary CLI, visit Using Rosemary. ",
    "url": "/docs/rosemary/testing/load_tests#introduction-to-locust",
    
    "relUrl": "/docs/rosemary/testing/load_tests#introduction-to-locust"
  },"76": {
    "doc": "Load tests",
    "title": "Run all load tests",
    "content": "To execute all load tests for all modules, run the following command: . rosemary locust . If everything worked correctly, you should see a Locust interface at http://localhost:8089 . ",
    "url": "/docs/rosemary/testing/load_tests#run-all-load-tests",
    
    "relUrl": "/docs/rosemary/testing/load_tests#run-all-load-tests"
  },"77": {
    "doc": "Load tests",
    "title": "Run load tests from specific module",
    "content": "It’s possible to run the load tests for a specific module. For this, the module must have a locustfile.py file defined within it. To execute the load tests for that module, run: . rosemary locust &lt;module_name&gt; . Replace &lt;module_name&gt; with the name of the module. ",
    "url": "/docs/rosemary/testing/load_tests#run-load-tests-from-specific-module",
    
    "relUrl": "/docs/rosemary/testing/load_tests#run-load-tests-from-specific-module"
  },"78": {
    "doc": "Load tests",
    "title": "Stop Locust",
    "content": "You need to stop Locust if you want to run tests for a particular module or if you have modified the locustfile.py for a module. To stop Locust, run: . rosemary locust:stop . ",
    "url": "/docs/rosemary/testing/load_tests#stop-locust",
    
    "relUrl": "/docs/rosemary/testing/load_tests#stop-locust"
  },"79": {
    "doc": "Load tests",
    "title": "Official documentation",
    "content": "We recommend visiting Locust’s official documentation for further test design to check the performance of uvlhub . ",
    "url": "/docs/rosemary/testing/load_tests#official-documentation",
    
    "relUrl": "/docs/rosemary/testing/load_tests#official-documentation"
  },"80": {
    "doc": "Managing database",
    "title": "Managing database",
    "content": " ",
    "url": "/docs/rosemary/managing_database",
    
    "relUrl": "/docs/rosemary/managing_database"
  },"81": {
    "doc": "Manual installation",
    "title": "Manual installation",
    "content": " ",
    "url": "/docs/installation/manual_installation",
    
    "relUrl": "/docs/installation/manual_installation"
  },"82": {
    "doc": "Manual installation",
    "title": "Table of contents",
    "content": ". | Update the system | Clone the repo | Install MariaDB . | Install official package | Start the MariaDB service | Configure MariaDB | Configure databases and users | . | Configure app environment . | Creates and activate a virtual environment | Install Python dependencies | Install Python dependencies in editable mode | . | Run app . | Environment variables | Apply migrations | Popular database | Boot development Flask server | . | . Python version . Python version 3.12 or higher is recommended. Ubuntu-only support . This tutorial is intended for use on Ubuntu 22.04 LTS or higher. ",
    "url": "/docs/installation/manual_installation#table-of-contents",
    
    "relUrl": "/docs/installation/manual_installation#table-of-contents"
  },"83": {
    "doc": "Manual installation",
    "title": "Update the system",
    "content": "sudo apt update -y sudo apt upgrade -y . ",
    "url": "/docs/installation/manual_installation#update-the-system",
    
    "relUrl": "/docs/installation/manual_installation#update-the-system"
  },"84": {
    "doc": "Manual installation",
    "title": "Clone the repo",
    "content": "git clone https://github.com/diverso-lab/uvlhub.git cd uvlhub . ",
    "url": "/docs/installation/manual_installation#clone-the-repo",
    
    "relUrl": "/docs/installation/manual_installation#clone-the-repo"
  },"85": {
    "doc": "Manual installation",
    "title": "Install MariaDB",
    "content": "Install official package . MariaDB is available in the official Ubuntu repositories, so you can easily install it with apt: . sudo apt install mariadb-server -y . Start the MariaDB service . sudo systemctl start mariadb . Configure MariaDB . After installing MariaDB, it is recommended to run the security script to perform some initial configurations: . sudo mysql_secure_installation . - Enter current password for root (enter for none): (enter) - Switch to unix_socket authentication [Y/n]: `y` - Change the root password? [Y/n]: `y` - New password: `uvlhubdb_root_password` - Re-enter new password: `uvlhubdb_root_password` - Remove anonymous users? [Y/n]: `y` - Disallow root login remotely? [Y/n]: `y` - Remove test database and access to it? [Y/n]: `y` - Reload privilege tables now? [Y/n] : `y` . Configure databases and users . Using uvlhubdb_root_password as root password: . sudo mysql -u root -p . CREATE DATABASE uvlhubdb; CREATE DATABASE uvlhubdb_test; CREATE USER 'uvlhubdb_user'@'localhost' IDENTIFIED BY 'uvlhubdb_password'; GRANT ALL PRIVILEGES ON uvlhubdb.* TO 'uvlhubdb_user'@'localhost'; GRANT ALL PRIVILEGES ON uvlhubdb_test.* TO 'uvlhubdb_user'@'localhost'; FLUSH PRIVILEGES; EXIT; . ",
    "url": "/docs/installation/manual_installation#install-mariadb",
    
    "relUrl": "/docs/installation/manual_installation#install-mariadb"
  },"86": {
    "doc": "Manual installation",
    "title": "Configure app environment",
    "content": "Creates and activate a virtual environment . python3 -m venv venv source venv/bin/activate . Install Python dependencies . pip install --upgrade pip pip install -r requirements.txt . Install Python dependencies in editable mode . pip install -e ./ . ",
    "url": "/docs/installation/manual_installation#configure-app-environment",
    
    "relUrl": "/docs/installation/manual_installation#configure-app-environment"
  },"87": {
    "doc": "Manual installation",
    "title": "Run app",
    "content": "Environment variables . cp .env.local.example .env . Apply migrations . rosemary db:migrate . Popular database . rosemary db:seed . Boot development Flask server . flask run --host=0.0.0.0 --reload --debug . If everything worked correctly, you should see the deployed version of uvlhub in development at http://localhost:5000 . ",
    "url": "/docs/installation/manual_installation#run-app",
    
    "relUrl": "/docs/installation/manual_installation#run-app"
  },"88": {
    "doc": "Migrations",
    "title": "Migrations",
    "content": " ",
    "url": "/docs/rosemary/managing_database/migrations",
    
    "relUrl": "/docs/rosemary/managing_database/migrations"
  },"89": {
    "doc": "Migrations",
    "title": "Table of contents",
    "content": "If during development there are new changes in the model, run: . rosemary db:migrate . This command will detect all changes in the model (new tables, modified fields, etc.) and apply those changes to the database. ",
    "url": "/docs/rosemary/managing_database/migrations#table-of-contents",
    
    "relUrl": "/docs/rosemary/managing_database/migrations#table-of-contents"
  },"90": {
    "doc": "Modules",
    "title": "Modules",
    "content": "Coming soon… . ",
    "url": "/docs/modules",
    
    "relUrl": "/docs/modules"
  },"91": {
    "doc": "Overview",
    "title": "Overview",
    "content": "The architecture of uvlhub consists of five main components. | Web application | Local Storage | Zenodo | Automated Analysis of Feature Models (AAFM) | REST API | . Figure 1: Overview of UVLHUB architecture. ",
    "url": "/docs/architecture/overview",
    
    "relUrl": "/docs/architecture/overview"
  },"92": {
    "doc": "Overview",
    "title": "Web application",
    "content": "The primary access point for the web application is through a web browser. Users navigate to a domain that redirects them to the Flask-developed application1. uvlhub integrates four distinct services: (2) local storage for UVL models and pertinent information, (3) Zenodo for permanent data persistence, (4) automatic feature model analysis, and (5) a RESTful service to extend functionality to other domains. ",
    "url": "/docs/architecture/overview#web-application",
    
    "relUrl": "/docs/architecture/overview#web-application"
  },"93": {
    "doc": "Overview",
    "title": "Local Storage",
    "content": "Users upload their models in the UVL format. All uploaded models must be syntactically valid, conforming to UVL grammar. However, models might still contain semantic errors such as dead features or conflicting constraints2. UVL files are stored locally, while related information like title, description, authors, and tags are stored in a relational database. ",
    "url": "/docs/architecture/overview#local-storage",
    
    "relUrl": "/docs/architecture/overview#local-storage"
  },"94": {
    "doc": "Overview",
    "title": "Zenodo",
    "content": "Although some model data is stored locally, it is backed up in the Zenodo general repository. This provides the UVL datasets with a DOI, facilitating the process of obtaining the identifier. If uvlhub becomes unavailable, the datasets remain on Zenodo, allowing local storage to be rebuilt without data loss. ",
    "url": "/docs/architecture/overview#zenodo",
    
    "relUrl": "/docs/architecture/overview#zenodo"
  },"95": {
    "doc": "Overview",
    "title": "Automated Analysis of Feature Models (AAFM)",
    "content": "Users can analyze2 the models within their datasets uploaded to uvlhub . This analysis, supported by the flamapy tool suite3, can determine model validity, feature count, or the number of different products derivable from the model. This component ensures each model’s syntactic correctness, delegating syntax verification responsibility to uvlhub , thus sparing users from performing this check. ",
    "url": "/docs/architecture/overview#automated-analysis-of-feature-models-aafm",
    
    "relUrl": "/docs/architecture/overview#automated-analysis-of-feature-models-aafm"
  },"96": {
    "doc": "Overview",
    "title": "REST API",
    "content": "Open Science advocates for open access to research data, making data generated in scientific research freely available and accessible to other researchers, practitioners, and the public. To support this, uvlhub offers a REST API accessible to any registered user with a developer role. This API allows free integration of validated and analyzed models (from component 4) into other domains. | Flask: Flask Project &#8617; . | AAFM: “Feature Models 20 Years Later: A Systematic Literature Review” &#8617; &#8617;2 . | Galindo, J. A., et al. (2023). “FLAMA: Feature Model Analysis Tool Suite” &#8617; . | . ",
    "url": "/docs/architecture/overview#rest-api",
    
    "relUrl": "/docs/architecture/overview#rest-api"
  },"97": {
    "doc": "Project structure",
    "title": "Project structure",
    "content": "This section provides an overview of the directory and file structure of the project. Each subsection describes the purpose and contents of specific directories and files, highlighting their roles within the overall architecture. Understanding this structure is crucial for effective development, maintenance, and deployment of the application. Below is a detailed explanation of each component in the project. ",
    "url": "/docs/architecture/project_structure",
    
    "relUrl": "/docs/architecture/project_structure"
  },"98": {
    "doc": "Project structure",
    "title": "Table of contents",
    "content": ". | .github/workflows | app | core | docker . | images . | Dockerfile.dev | Dockerfile.mariadb | Dockerfile.prod | . | letsencrypt | nginx | public | docker-compose.dev.yml | docker-compose.prod.yml | . | vagrant . | Vagrantfile | *.yml | . | migrations | rosemary | scripts | .env.X.example | .flake8 | .gitignore | requirements.txt | setup.py | . ",
    "url": "/docs/architecture/project_structure#table-of-contents",
    
    "relUrl": "/docs/architecture/project_structure#table-of-contents"
  },"99": {
    "doc": "Project structure",
    "title": ".github/workflows",
    "content": "This directory contains GitHub Actions workflows. These YAML files define automated actions that run on specific repository events, such as pushes or pull requests. ",
    "url": "/docs/architecture/project_structure#githubworkflows",
    
    "relUrl": "/docs/architecture/project_structure#githubworkflows"
  },"100": {
    "doc": "Project structure",
    "title": "app",
    "content": "This directory likely contains the main application code. It includes modules, views, controllers, and other fundamental components of the application’s business logic. ",
    "url": "/docs/architecture/project_structure#app",
    
    "relUrl": "/docs/architecture/project_structure#app"
  },"101": {
    "doc": "Project structure",
    "title": "core",
    "content": "This directory usually contains core components and services used throughout the application. It can include utilities, global configurations, and base classes. ",
    "url": "/docs/architecture/project_structure#core",
    
    "relUrl": "/docs/architecture/project_structure#core"
  },"102": {
    "doc": "Project structure",
    "title": "docker",
    "content": "images . Dockerfile.dev . Docker file for building the application’s development image. It includes all dependencies and configurations needed for a development environment. Dockerfile.mariadb . Docker file for building a MariaDB image, a SQL database. It is used to integrate the database into the development or production environment. Dockerfile.prod . Docker file for building the application’s production image. It is optimized for performance and security. letsencrypt . This directory is related to Let’s Encrypt, a free certificate authority. It contains scripts and configurations for the automatic generation of SSL certificates. nginx . This directory contains configurations for the NGINX web server, which is used to serve the application, handle HTTP traffic, and perform other network-related tasks. public . This directory is for generating SSL certificates, it acts as a temporary public folder. docker-compose.dev.yml . Docker Compose configuration file for the development environment. It defines how development containers should be orchestrated. docker-compose.prod.yml . Docker Compose configuration file for the production environment. It defines how containers should be orchestrated in production. ",
    "url": "/docs/architecture/project_structure#docker",
    
    "relUrl": "/docs/architecture/project_structure#docker"
  },"103": {
    "doc": "Project structure",
    "title": "vagrant",
    "content": "Vagrantfile . This file is a specification that describes how to create a virtual machine (VM) under specific characteristics. It defines the necessary configurations for the development environment, such as the base box, network, shared folders, and provisioning scripts. *.yml . These files, known as playbooks, are used by Ansible to automate system configuration and management. A playbook is a YAML file that contains a series of instructions and tasks that Ansible will execute on the target machines. Playbooks are used to automate complex and repetitive tasks, ensuring that the development or production environment is configured in a consistent manner. ",
    "url": "/docs/architecture/project_structure#vagrant",
    
    "relUrl": "/docs/architecture/project_structure#vagrant"
  },"104": {
    "doc": "Project structure",
    "title": "migrations",
    "content": "This directory contains database migration files, which allow incremental changes to the database schema in a controlled and reproducible manner. ",
    "url": "/docs/architecture/project_structure#migrations",
    
    "relUrl": "/docs/architecture/project_structure#migrations"
  },"105": {
    "doc": "Project structure",
    "title": "rosemary",
    "content": "This directory contains the code for the Rosemary CLI package. It is a version still under development and is not available in pypi at the moment. ",
    "url": "/docs/architecture/project_structure#rosemary",
    
    "relUrl": "/docs/architecture/project_structure#rosemary"
  },"106": {
    "doc": "Project structure",
    "title": "scripts",
    "content": "Contains auxiliary scripts that automate various tasks such as dependency installation, deployment, maintenance, and more. ",
    "url": "/docs/architecture/project_structure#scripts",
    
    "relUrl": "/docs/architecture/project_structure#scripts"
  },"107": {
    "doc": "Project structure",
    "title": ".env.X.example",
    "content": "These files provide an example of the environment variables needed to run the application. They are used as a reference for setting up the development environment. ",
    "url": "/docs/architecture/project_structure#envxexample",
    
    "relUrl": "/docs/architecture/project_structure#envxexample"
  },"108": {
    "doc": "Project structure",
    "title": ".flake8",
    "content": "Contains configurations for Flake8, a code style and checking tool for Python. It helps maintain code consistency and find common errors. ",
    "url": "/docs/architecture/project_structure#flake8",
    
    "relUrl": "/docs/architecture/project_structure#flake8"
  },"109": {
    "doc": "Project structure",
    "title": ".gitignore",
    "content": "A list of files and directories that Git should ignore. This prevents certain files (like local configurations and temporary files) from being included in version control. ",
    "url": "/docs/architecture/project_structure#gitignore",
    
    "relUrl": "/docs/architecture/project_structure#gitignore"
  },"110": {
    "doc": "Project structure",
    "title": "requirements.txt",
    "content": "A list of Python dependencies needed for the project. Used by pip to install all required libraries. ",
    "url": "/docs/architecture/project_structure#requirementstxt",
    
    "relUrl": "/docs/architecture/project_structure#requirementstxt"
  },"111": {
    "doc": "Project structure",
    "title": "setup.py",
    "content": "A setup script used for distributing Python packages. It defines package properties such as name, version, and dependencies. En este caso, sirve para poder usar el paquete rosemary . ",
    "url": "/docs/architecture/project_structure#setuppy",
    
    "relUrl": "/docs/architecture/project_structure#setuppy"
  },"112": {
    "doc": "Reset database",
    "title": "Reset database",
    "content": "The rosemary db:reset command is a powerful tool for resetting your project’s database to its initial state. This command deletes all the data in your database, making it ideal for fixing any inconsistencies we may have created during development. ",
    "url": "/docs/rosemary/managing_database/reset_database",
    
    "relUrl": "/docs/rosemary/managing_database/reset_database"
  },"113": {
    "doc": "Reset database",
    "title": "Table of contents",
    "content": ". | Basic Usage | Clear migrations | . ",
    "url": "/docs/rosemary/managing_database/reset_database#table-of-contents",
    
    "relUrl": "/docs/rosemary/managing_database/reset_database#table-of-contents"
  },"114": {
    "doc": "Reset database",
    "title": "Basic Usage",
    "content": "To reset your database and clear all table data except for migration records, run: . rosemary db:reset . The rosemary db:reset command also clears the uploads directory as part of the reset process, ensuring that any files uploaded during development or testing are removed. ",
    "url": "/docs/rosemary/managing_database/reset_database#basic-usage",
    
    "relUrl": "/docs/rosemary/managing_database/reset_database#basic-usage"
  },"115": {
    "doc": "Reset database",
    "title": "Clear migrations",
    "content": "If you need to completely rebuild your database from scratch, including removing all migration history and starting fresh, you can use the --clear-migrations option: . rosemary db:reset --clear-migrations . Be careful! This command will… . | Delete all data from the database, including the migration history. | Clear the migrations directory. | Initialize a new set of migrations. | Apply the migrations to rebuild the database schema. | . ",
    "url": "/docs/rosemary/managing_database/reset_database#clear-migrations",
    
    "relUrl": "/docs/rosemary/managing_database/reset_database#clear-migrations"
  },"116": {
    "doc": "Rosemary CLI",
    "title": "Rosemary CLI",
    "content": "Rosemary is a CLI (Command Line Interface) tool developed to facilitate project management and development tasks. ",
    "url": "/docs/rosemary",
    
    "relUrl": "/docs/rosemary"
  },"117": {
    "doc": "Rosemary CLI",
    "title": "Advantages of Using a CLI",
    "content": "Common usage point . A CLI provides a standardized interface for executing commands, making it easier for users to perform a wide range of tasks from a single point. Command unification . With a CLI, commands are unified under a single tool, reducing the need to remember different commands for different environments or tools. This unification streamlines workflows and enhances productivity. Environment problem resolution . Rosemary detects the environment in which it is running, whether local, Docker, or Vagrant. This capability acts as a layer that simplifies environment management, automatically adjusting its behavior to suit the detected environment and minimizing the potential for environment-specific issues. Efficiency and speed . CLIs are typically faster than graphical user interfaces (GUIs) because they require fewer resources and can execute commands more quickly without the overhead of graphical elements. Automation . A CLI can be easily scripted, allowing for the automation of repetitive tasks. This feature is particularly beneficial in development and project management, where certain tasks need to be performed frequently and consistently. By incorporating these advantages, Rosemary enhances the efficiency and effectiveness of project management and development processes, providing a robust tool for developers and project managers alike. ",
    "url": "/docs/rosemary#advantages-of-using-a-cli",
    
    "relUrl": "/docs/rosemary#advantages-of-using-a-cli"
  },"118": {
    "doc": "Routing",
    "title": "Routing",
    "content": "The rosemary command route:list allows you to list all the routes available in the project. This command is useful for getting a quick overview of available endpoints and their corresponding HTTP methods. ",
    "url": "/docs/rosemary/routing",
    
    "relUrl": "/docs/rosemary/routing"
  },"119": {
    "doc": "Routing",
    "title": "Table of contents",
    "content": ". | List all routes | Group routes by module | List routes of a specific module | . ",
    "url": "/docs/rosemary/routing#table-of-contents",
    
    "relUrl": "/docs/rosemary/routing#table-of-contents"
  },"120": {
    "doc": "Routing",
    "title": "List all routes",
    "content": "To list all the routes of all the modules, run: . rosemary route:list . ",
    "url": "/docs/rosemary/routing#list-all-routes",
    
    "relUrl": "/docs/rosemary/routing#list-all-routes"
  },"121": {
    "doc": "Routing",
    "title": "Group routes by module",
    "content": "To get a grouped view of the routes by module, you can use the --group option. This is especially useful for applications with a complex modular structure, as it allows you to quickly see how the routes are organized within different parts of your application. rosemary route:list --group . ",
    "url": "/docs/rosemary/routing#group-routes-by-module",
    
    "relUrl": "/docs/rosemary/routing#group-routes-by-module"
  },"122": {
    "doc": "Routing",
    "title": "List routes of a specific module",
    "content": "It may be useful to see the routes associated with a specific module. To do this, simply provide the module name as an argument: . rosemary route:list &lt;module_name&gt; . Replace &lt;module_name&gt; with the actual name of the module for which you want to see the routes. ",
    "url": "/docs/rosemary/routing#list-routes-of-a-specific-module",
    
    "relUrl": "/docs/rosemary/routing#list-routes-of-a-specific-module"
  },"123": {
    "doc": "Seeders",
    "title": "Seeders",
    "content": " ",
    "url": "/docs/rosemary/managing_database/seeders",
    
    "relUrl": "/docs/rosemary/managing_database/seeders"
  },"124": {
    "doc": "Seeders",
    "title": "Table of contents",
    "content": ". | Basic Usage . | Populate from all modules | Populate from specific module | . | Reset database before populating . | Reset all modules test data | Reset test data of specific module | . | . ",
    "url": "/docs/rosemary/managing_database/seeders#table-of-contents",
    
    "relUrl": "/docs/rosemary/managing_database/seeders#table-of-contents"
  },"125": {
    "doc": "Seeders",
    "title": "Basic Usage",
    "content": "It is possible to populate the database with predefined test data. It is very useful for testing certain that require existing data. Populate from all modules . To populate all test data of all modules, run: . rosemary db:seed . Populate from specific module . If we only want to popularize the test data of a specific module, run: . rosemary db:seed &lt;module_name&gt; . Replace &lt;module_name&gt; with the name of the module you want to populate (for example, auth for the authentication module). ",
    "url": "/docs/rosemary/managing_database/seeders#basic-usage",
    
    "relUrl": "/docs/rosemary/managing_database/seeders#basic-usage"
  },"126": {
    "doc": "Seeders",
    "title": "Reset database before populating",
    "content": "If you want to make sure that the database is in a clean state before populating it with test data, you can use the --reset flag. This will reset the database to its initial state before running the seeders: . Reset all modules test data . rosemary db:seed --reset . Reset test data of specific module . You can also combine the --reset flag with a module specification if you want to reset the database before populating only the test data of a specific module: . rosemary db:seed &lt;module_name&gt; --reset . ",
    "url": "/docs/rosemary/managing_database/seeders#reset-database-before-populating",
    
    "relUrl": "/docs/rosemary/managing_database/seeders#reset-database-before-populating"
  },"127": {
    "doc": "SSL certificate",
    "title": "SSL certificate",
    "content": "An SSL certificate (https) is essential for securing the communication between a website and its users. It encrypts transmitted data, protecting sensitive information from interception. Additionally, it authenticates the website’s identity, ensuring users they are interacting with the legitimate site. SSL certificates also improve search engine rankings, enhancing the website’s visibility and credibility. ",
    "url": "/docs/deployment/ssl_certificate",
    
    "relUrl": "/docs/deployment/ssl_certificate"
  },"128": {
    "doc": "SSL certificate",
    "title": "Table of contents",
    "content": ". | Scripts folder | Generate certificate | Renew certificate | . The use of SSL certificates is configured for Docker deployment only. Visit ‘Installation with Docker. ",
    "url": "/docs/deployment/ssl_certificate#table-of-contents",
    
    "relUrl": "/docs/deployment/ssl_certificate#table-of-contents"
  },"129": {
    "doc": "SSL certificate",
    "title": "Scripts folder",
    "content": "To begin with, we must go to the scripts folder: . cd scripts . ",
    "url": "/docs/deployment/ssl_certificate#scripts-folder",
    
    "relUrl": "/docs/deployment/ssl_certificate#scripts-folder"
  },"130": {
    "doc": "SSL certificate",
    "title": "Generate certificate",
    "content": "To generate a new certificate, run: . chmod +x ssl_setup.sh ./ssl_setup.sh . ",
    "url": "/docs/deployment/ssl_certificate#generate-certificate",
    
    "relUrl": "/docs/deployment/ssl_certificate#generate-certificate"
  },"131": {
    "doc": "SSL certificate",
    "title": "Renew certificate",
    "content": "To renew a certificate that is less than 60 days from expiry, execute: . chmod +x ssl_renew.sh ./ssl_renew.sh . ",
    "url": "/docs/deployment/ssl_certificate#renew-certificate",
    
    "relUrl": "/docs/deployment/ssl_certificate#renew-certificate"
  },"132": {
    "doc": "Test users",
    "title": "Test users",
    "content": "Test users are already available when the system is installed, regardless of the configuration environment. This is possible thanks to the rosemary db:seed command that is launched. User: user1@example.com Pass: 1234 . User: user2@example.com Pass: 1234 . Repopulate the database . You can change these test users and popular more modules. Visit Seeders. ",
    "url": "/docs/installation/test_users",
    
    "relUrl": "/docs/installation/test_users"
  },"133": {
    "doc": "Test coverage",
    "title": "Test coverage",
    "content": "The rosemary coverage command facilitates running code coverage analysis for your Flask project using pytest-cov. This command simplifies the process of assessing test coverage. ",
    "url": "/docs/rosemary/testing/test_coverage",
    
    "relUrl": "/docs/rosemary/testing/test_coverage"
  },"134": {
    "doc": "Test coverage",
    "title": "Table of contents",
    "content": ". | Test coverage of all modules | Test coverage of a specific module | Command Options . | --html | . | . ",
    "url": "/docs/rosemary/testing/test_coverage#table-of-contents",
    
    "relUrl": "/docs/rosemary/testing/test_coverage#table-of-contents"
  },"135": {
    "doc": "Test coverage",
    "title": "Test coverage of all modules",
    "content": "To run coverage analysis for all modules within the app/blueprints directory and generate an HTML report, use: . rosemary coverage . ",
    "url": "/docs/rosemary/testing/test_coverage#test-coverage-of-all-modules",
    
    "relUrl": "/docs/rosemary/testing/test_coverage#test-coverage-of-all-modules"
  },"136": {
    "doc": "Test coverage",
    "title": "Test coverage of a specific module",
    "content": "If you wish to run coverage analysis for a specific module, include the module name: . rosemary coverage &lt;module_name&gt; . ",
    "url": "/docs/rosemary/testing/test_coverage#test-coverage-of-a-specific-module",
    
    "relUrl": "/docs/rosemary/testing/test_coverage#test-coverage-of-a-specific-module"
  },"137": {
    "doc": "Test coverage",
    "title": "Command Options",
    "content": "--html . This option generates an HTML coverage report. The report is saved in the htmlcov directory at the root of your project. rosemary coverage --html . ",
    "url": "/docs/rosemary/testing/test_coverage#command-options",
    
    "relUrl": "/docs/rosemary/testing/test_coverage#command-options"
  },"138": {
    "doc": "Testing",
    "title": "Testing",
    "content": " ",
    "url": "/docs/rosemary/testing",
    
    "relUrl": "/docs/rosemary/testing"
  },"139": {
    "doc": "Testing workflow",
    "title": "Testing workflow",
    "content": "Path to file (view file on GitHub) . The original file is located at the following path: .github / workflows / test.yml . This GitHub Actions workflow is designed to automate the Continuous Integration (CI) process for a Flask application. It triggers on pushes and pull requests to the main and develop branches. The essential elements of this workflow are as follows: . | Workflow Name | Triggers | Jobs . | Services | Steps | Environment Variables for Tests | . | . ",
    "url": "/docs/ci_cd/continuous_integration/testing_workflow",
    
    "relUrl": "/docs/ci_cd/continuous_integration/testing_workflow"
  },"140": {
    "doc": "Testing workflow",
    "title": "Workflow Name",
    "content": ". | name: Flask CI | . ",
    "url": "/docs/ci_cd/continuous_integration/testing_workflow#workflow-name",
    
    "relUrl": "/docs/ci_cd/continuous_integration/testing_workflow#workflow-name"
  },"141": {
    "doc": "Testing workflow",
    "title": "Triggers",
    "content": ". | on: . | push: Triggers on pushes to main and develop branches. | pull_request: Triggers on pull requests to main and develop branches. | . | . ",
    "url": "/docs/ci_cd/continuous_integration/testing_workflow#triggers",
    
    "relUrl": "/docs/ci_cd/continuous_integration/testing_workflow#triggers"
  },"142": {
    "doc": "Testing workflow",
    "title": "Jobs",
    "content": ". | pytest: This job runs on the latest Ubuntu environment (ubuntu-latest). | . Services . | mysql: Sets up a MySQL 5.7 service with the following environment variables and options for health checks: . | MYSQL_ROOT_PASSWORD: uvlhub_root_password | MYSQL_DATABASE: uvlhubdb_test | MYSQL_USER: uvlhub_user | MYSQL_PASSWORD: uvlhub_password | Ports: 3306:3306 | Health check options: --health-cmd=\"mysqladmin ping\" --health-interval=10s --health-timeout=5s --health-retries=3 | . | . Steps . | Checkout Repository . | Uses the actions/checkout@v4 action to checkout the repository. | . | Setup Python . | Uses the actions/setup-python@v5 action to set up Python 3.12. | . | Prepare Environment . | Runs a command to modify the requirements.txt file, removing a specific line. | . | Install Dependencies . | Upgrades pip and installs dependencies from requirements.txt. | . | Run Tests . | Sets environment variables for testing and runs pytest on the Flask application. | . | . Environment Variables for Tests . | FLASK_ENV: testing | BLUEPRINTS_DIR: app/blueprints | MARIADB_HOSTNAME: 127.0.0.1 | MARIADB_PORT: 3306 | MARIADB_TEST_DATABASE: uvlhubdb_test | MARIADB_USER: uvlhub_user | MARIADB_PASSWORD: uvlhub_password | . ",
    "url": "/docs/ci_cd/continuous_integration/testing_workflow#jobs",
    
    "relUrl": "/docs/ci_cd/continuous_integration/testing_workflow#jobs"
  },"143": {
    "doc": "Troubleshooting",
    "title": "Troubleshooting",
    "content": "This section provides users with valuable guidance on identifying, diagnosing, and resolving common issues that may arise. This section is intended to help users troubleshoot various problems efficiently, ensuring a smoother and more productive experience. It includes step-by-step instructions, common error messages, and practical solutions to address a wide range of technical difficulties. ",
    "url": "/docs/troubleshooting",
    
    "relUrl": "/docs/troubleshooting"
  },"144": {
    "doc": "Unit tests",
    "title": "Unit tests",
    "content": " ",
    "url": "/docs/rosemary/testing/unit_tests",
    
    "relUrl": "/docs/rosemary/testing/unit_tests"
  },"145": {
    "doc": "Unit tests",
    "title": "Table of contents",
    "content": ". | Testing all modules | Testing a specific module | . ",
    "url": "/docs/rosemary/testing/unit_tests#table-of-contents",
    
    "relUrl": "/docs/rosemary/testing/unit_tests#table-of-contents"
  },"146": {
    "doc": "Unit tests",
    "title": "Testing all modules",
    "content": "To run tests across all modules in the project, you can use the following command: . rosemary test . This command will execute all tests found within the app/blueprints directory, covering all the modules of the project. ",
    "url": "/docs/rosemary/testing/unit_tests#testing-all-modules",
    
    "relUrl": "/docs/rosemary/testing/unit_tests#testing-all-modules"
  },"147": {
    "doc": "Unit tests",
    "title": "Testing a specific module",
    "content": "If you’re focusing on a particular module and want to run tests only for that module, you can specify the module name as an argument: . rosemary test &lt;module_name&gt; . ",
    "url": "/docs/rosemary/testing/unit_tests#testing-a-specific-module",
    
    "relUrl": "/docs/rosemary/testing/unit_tests#testing-a-specific-module"
  },"148": {
    "doc": "Updating dependencies",
    "title": "Updating dependencies",
    "content": "To update all project dependencies, run: . rosemary update . It is the responsibility of the developer to check that the update of the dependencies has not broken any functionality and each dependency maintains backwards compatibility. Use the script with care! . ",
    "url": "/docs/rosemary/updating_dependencies",
    
    "relUrl": "/docs/rosemary/updating_dependencies"
  },"149": {
    "doc": "Using Rosemary",
    "title": "Using Rosemary",
    "content": " ",
    "url": "/docs/rosemary/using_rosemary",
    
    "relUrl": "/docs/rosemary/using_rosemary"
  },"150": {
    "doc": "Using Rosemary",
    "title": "Table of contents",
    "content": ". | Using Rosemary in manual environment | Using Rosemary in Docker environment | Using Rosemary in Vagrant environment | . ",
    "url": "/docs/rosemary/using_rosemary#table-of-contents",
    
    "relUrl": "/docs/rosemary/using_rosemary#table-of-contents"
  },"151": {
    "doc": "Using Rosemary",
    "title": "Using Rosemary in manual environment",
    "content": "To use Rosemary CLI in a manual environment, we must activate the Python virtual environment: . python -m venv venv source venv/bin/activate . This will create a venv folder. Rosemary is a development package, so we must install packages in editable mode: . pip install -e ./ . ",
    "url": "/docs/rosemary/using_rosemary#using-rosemary-in-manual-environment",
    
    "relUrl": "/docs/rosemary/using_rosemary#using-rosemary-in-manual-environment"
  },"152": {
    "doc": "Using Rosemary",
    "title": "Using Rosemary in Docker environment",
    "content": "To use the Rosemary CLI in Docker environment, you need to be inside the web_app_container Docker container. This ensures that Rosemary operates in the correct environment and has access to all necessary files and settings. First, make sure your Docker environment is running. Then, access the web_app_container using the following command: . docker exec -it web_app_container /bin/sh . In the terminal, you should see the prefix /app #. You are now ready to use Rosemary’s commands. ",
    "url": "/docs/rosemary/using_rosemary#using-rosemary-in-docker-environment",
    
    "relUrl": "/docs/rosemary/using_rosemary#using-rosemary-in-docker-environment"
  },"153": {
    "doc": "Using Rosemary",
    "title": "Using Rosemary in Vagrant environment",
    "content": "To use Rosemary CLI in Vagrant rosemary, you need to be inside the virtual machine. First, make sure the machine is booted: . cd vagrant vagrant up . Second, you must access the machine . vagrant ssh . Provisioning the machine already activates the Python virtual environment needed to run Rosemary. You should see the line (venv) vagrant@ubuntu-mantic:/vagrant$. That means you can now use Rosemary along with all its commands. ",
    "url": "/docs/rosemary/using_rosemary#using-rosemary-in-vagrant-environment",
    
    "relUrl": "/docs/rosemary/using_rosemary#using-rosemary-in-vagrant-environment"
  },"154": {
    "doc": "Zenodo",
    "title": "Zenodo",
    "content": "Zenodo is an open access repository that allows researchers, scientists, academics and anyone interested in sharing their research to upload and store research data, publications, software and other scientific results. It was created by OpenAIRE and CERN (European Organization for Nuclear Research) to support the open access movement and facilitate the sharing and preservation of scientific data. ",
    "url": "/docs/modules/zenodo",
    
    "relUrl": "/docs/modules/zenodo"
  },"155": {
    "doc": "Zenodo",
    "title": "Table of contents",
    "content": ". | Obtain a token | Generate .env file | Include your access token | . ",
    "url": "/docs/modules/zenodo#table-of-contents",
    
    "relUrl": "/docs/modules/zenodo#table-of-contents"
  },"156": {
    "doc": "Zenodo",
    "title": "Obtain a token",
    "content": "To use Zenodo module, it is important to obtain a token in Zenodo first. We recommend creating the token in the Sandbox version of Zenodo (https://sandbox.zenodo.org/), in order to generate fictitious DOIs and not make intensive use of the real Zenodo SLA. | Create an Account on Zenodo . | Go to Zenodo. | Click on Sign up and complete the registration. | . | Log in to Zenodo . | Go to Zenodo. | Click on Log in and log in with your account. | . | Access the Tokens Section . | Click on your username in the top right corner. | Select Applications. | . | Create a New Access Token . | Under Personal access tokens, click on New token. | Assign a name for your token. | Select all permissions to grant full access. | Read: Allows read-only access. | Write: Allows creating and modifying records. | Delete: Allows deleting records. | . | Click Create. | . | Save the Access Token . | Copy and save the generated token in a secure place. | . | . ",
    "url": "/docs/modules/zenodo#obtain-a-token",
    
    "relUrl": "/docs/modules/zenodo#obtain-a-token"
  },"157": {
    "doc": "Zenodo",
    "title": "Generate .env file",
    "content": "To generate the Zenodo .env file in app/blueprints/zenodo, run in root project: . cp app/blueprints/zenodo/.env.example app/blueprints/zenodo/.env . ",
    "url": "/docs/modules/zenodo#generate-env-file",
    
    "relUrl": "/docs/modules/zenodo#generate-env-file"
  },"158": {
    "doc": "Zenodo",
    "title": "Include your access token",
    "content": "In the generated .envfile, you must include the access token obtained in Zenodo: . ZENODO_ACCESS_TOKEN=&lt;GET_ACCESS_TOKEN_IN_ZENODO&gt; . A composition of variables is necessary! . To perform the composition of all environment variables, refer to section Composing environment. ",
    "url": "/docs/modules/zenodo#include-your-access-token",
    
    "relUrl": "/docs/modules/zenodo#include-your-access-token"
  }
}
